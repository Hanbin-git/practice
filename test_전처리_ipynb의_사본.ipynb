{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1dd684qSyNKG-SEUtvV1zuUQSfCsW0ANS",
      "authorship_tag": "ABX9TyNBhbEZYnljHqTu80eLWHAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "956db5ac7bbb4eebb589418a309ad837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1cb40e358b74de78fb1a64bee56b847",
              "IPY_MODEL_13a31fb744e24a68ba0aa6f7396e074d",
              "IPY_MODEL_9493eb0ff3dc4ab3a36395ce7cc4a242"
            ],
            "layout": "IPY_MODEL_c729cc26c26847f39492ea8737e0fab9"
          }
        },
        "b1cb40e358b74de78fb1a64bee56b847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735254c638604abf888612285b70dbf2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1dbb39f80ae04635a001e905cafb1142",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "13a31fb744e24a68ba0aa6f7396e074d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2296a15d13654d139317c5305e58fd53",
            "max": 114374272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15e25a5062ee4f6a8ee1147e196a7ace",
            "value": 114374272
          }
        },
        "9493eb0ff3dc4ab3a36395ce7cc4a242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42fad4ac3cdd432382122baa0981ca2b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eeb91e01236c43b9b9e87718ef244f96",
            "value": "‚Äá114M/114M‚Äá[00:01&lt;00:00,‚Äá96.2MB/s]"
          }
        },
        "c729cc26c26847f39492ea8737e0fab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735254c638604abf888612285b70dbf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbb39f80ae04635a001e905cafb1142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2296a15d13654d139317c5305e58fd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e25a5062ee4f6a8ee1147e196a7ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42fad4ac3cdd432382122baa0981ca2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb91e01236c43b9b9e87718ef244f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/practice/blob/main/test_%EC%A0%84%EC%B2%98%EB%A6%AC_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peaMNLWchXQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juS4rlAhexwK",
        "outputId": "f0a10edc-09e8-4c70-d3f8-b73a5eb3ed2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF"
      ],
      "metadata": {
        "id": "eyLBp4j3i6F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ÏÑ§Ï†ï =====\n",
        "test_csv_path = '/content/drive/MyDrive/open/test.csv'\n",
        "test_img_dir = '/content/drive/MyDrive/open/test'  # test Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî\n",
        "save_root = '/content/drive/MyDrive/fuck/preprocessed_test'  # test Ï†ÑÏ≤òÎ¶¨ Ï†ÄÏû• ÏúÑÏπò\n",
        "os.makedirs(save_root, exist_ok=True)"
      ],
      "metadata": {
        "id": "Ybtf0x5si9CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Grayscale + Resize transform Ï†ïÏùò\n",
        "# class SquarePad:\n",
        "#     def __call__(self, image):\n",
        "#         w, h = image.size\n",
        "#         max_wh = max(w, h)\n",
        "#         pad_left = (max_wh - w) // 2\n",
        "#         pad_top = (max_wh - h) // 2\n",
        "#         padding = (pad_left, pad_top, max_wh - w - pad_left, max_wh - h - pad_top)\n",
        "#         return TF.pad(image, padding, fill=0)\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Grayscale(num_output_channels=1),\n",
        "#     SquarePad(),\n",
        "#     transforms.Resize((384, 384)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.5], [0.5])\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "Dxb4JBcejAnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ===== Test CSV ÏùΩÍ∏∞ =====\n",
        "# test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# # ‚úÖ ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ: img_pathÏóêÏÑú ÌååÏùºÎ™ÖÎßå Ï∂îÏ∂ú\n",
        "# test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.basename(x))\n",
        "# test_df['full_img_path'] = test_df['img_path'].apply(lambda x: os.path.join(test_img_dir, x))\n",
        "# test_df['img_name_no_ext'] = test_df['img_path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])  # 'TEST_00000'\n",
        "\n",
        "# # ===== Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë =====\n",
        "# counter = 0  # Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ Ïπ¥Ïö¥ÌÑ∞\n",
        "# batch_index = 0  # batch_000, batch_001...\n",
        "# batch_limit = 800  # Ìïú Ìè¥ÎçîÏóê Ï†ÄÏû•Ìï† ÏµúÎåÄ Í∞úÏàò\n",
        "\n",
        "# current_batch_dir = os.path.join(save_root, f\"batch_{batch_index:03}\")\n",
        "# os.makedirs(current_batch_dir, exist_ok=True)\n",
        "\n",
        "# print(\"üì¶ Test Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë...\")\n",
        "\n",
        "# for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "#     img_id = row['img_name_no_ext']  # TEST_00000\n",
        "#     img_path = row['full_img_path']\n",
        "\n",
        "#     try:\n",
        "#         img = Image.open(img_path).convert('RGB')\n",
        "#         img_tensor = transform(img)\n",
        "\n",
        "#         # Ìè¥Îçî Î∂ÑÌï† Ï°∞Í±¥\n",
        "#         if counter > 0 and counter % batch_limit == 0:\n",
        "#             batch_index += 1\n",
        "#             current_batch_dir = os.path.join(save_root, f\"batch_{batch_index:03}\")\n",
        "#             os.makedirs(current_batch_dir, exist_ok=True)\n",
        "\n",
        "#         # Ï†ÄÏû• ÌååÏùºÎ™Ö: TEST_00000.npy\n",
        "#         save_name = f\"{img_id}.npy\"\n",
        "#         save_path = os.path.join(current_batch_dir, save_name)\n",
        "#         np.save(save_path, img_tensor.numpy())\n",
        "\n",
        "#         counter += 1\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Ïò§Î•ò: {img_path} ‚Üí {e}\")\n",
        "\n",
        "# print(f\"‚úÖ Test Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å: Ï¥ù {counter}Í∞ú Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•Îê®\")\n",
        "# print(f\"üìÇ Î∞∞Ïπò Ìè¥Îçî Ïàò: {batch_index + 1}\")"
      ],
      "metadata": {
        "id": "SqM_vaNwjLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # üöó TestÏö© npy ÌååÏùº Í≤ΩÎ°ú (ÏòàÏãú)\n",
        "# npy_path = '/content/drive/MyDrive/fuck/preprocessed_test/batch_000/TEST_00000.npy'\n",
        "\n",
        "# # npy Î∂àÎü¨Ïò§Í∏∞\n",
        "# img = np.load(npy_path)\n",
        "\n",
        "# # (1, H, W) ‚Üí (H, W)\n",
        "# if img.shape[0] == 1:\n",
        "#     img = img.squeeze(0)\n",
        "\n",
        "# # ÏãúÍ∞ÅÌôî\n",
        "# plt.imshow(img, cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.title(\"Test Grayscale ÏãúÍ∞ÅÌôî\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "spSREKsVZ9R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# # Test JPG ÌååÏùº Ïàò ÌôïÏù∏\n",
        "# jpg_count = 0\n",
        "# jpg_paths = []\n",
        "\n",
        "# test_dir = '/content/drive/MyDrive/open/test'\n",
        "# for file in os.listdir(test_dir):\n",
        "#     if file.lower().endswith('.jpg'):\n",
        "#         jpg_count += 1\n",
        "#         jpg_paths.append(file)  # ÌååÏùºÎ™ÖÎßå Ï†ÄÏû• (TEST_00000.jpg Îì±)\n",
        "\n",
        "# print(f\"‚úÖ Test Ìè¥Îçî ÎÇ¥ JPG ÌååÏùº Ïàò: {jpg_count}\")\n",
        "\n",
        "# # Ï†ÑÏ≤òÎ¶¨Îêú .npy ÌååÏùº Ïàò ÌôïÏù∏\n",
        "# npy_dir = '/content/drive/MyDrive/fuck/preprocessed_test'\n",
        "# npy_count = 0\n",
        "# npy_files = []\n",
        "\n",
        "# # Î™®Îì† ÌïòÏúÑ Ìè¥ÎçîÍπåÏßÄ ÌÉêÏÉâ\n",
        "# for root, dirs, files in os.walk(npy_dir):\n",
        "#     for file in files:\n",
        "#         if file.endswith('.npy'):\n",
        "#             npy_count += 1\n",
        "#             npy_files.append(os.path.join(root, file))\n",
        "\n",
        "# print(f\"‚úÖ Ï†ÄÏû•Îêú .npy ÌååÏùº Ïàò: {npy_count}\")\n",
        "\n",
        "# # ‚õî Ï§ëÎ≥µ ÎòêÎäî Ï∂îÍ∞Ä ÌååÏùº ÏùòÏã¨ ÌôïÏù∏\n",
        "# # jpg_paths = ['TEST_00000.jpg', ...] ‚Üí ÎåÄÏùëÎêòÎäî npyÎäî 'TEST_00000.npy'\n",
        "# expected_npy_names = set([os.path.splitext(f)[0] + '.npy' for f in jpg_paths])\n",
        "# actual_npy_names = set([os.path.basename(f) for f in npy_files])\n",
        "\n",
        "# extra = actual_npy_names - expected_npy_names\n",
        "# missing = expected_npy_names - actual_npy_names\n",
        "\n",
        "# if len(extra) == 0 and len(missing) == 0:\n",
        "#     print(\"‚úÖ Î™®Îì† ÌååÏùº Ï†ïÏÉÅ! JPG ‚Üî npy Í∞úÏàò Î∞è Ïù¥Î¶Ñ ÏùºÏπò üéâ\")\n",
        "# else:\n",
        "#     print(f\"‚ö†Ô∏è ÏùòÏã¨ÎêòÎäî Ï∂îÍ∞Ä Ï†ÄÏû• ÌååÏùº Ïàò: {len(extra)}\")\n",
        "#     print(\"ÏòàÏãú ÌååÏùº (extra):\", list(extra)[:5])\n",
        "#     print(f\"‚ö†Ô∏è ÎàÑÎùΩÎêú ÏòàÏÉÅ ÌååÏùº Ïàò: {len(missing)}\")\n",
        "#     print(\"ÏòàÏãú ÌååÏùº (missing):\", list(missing)[:5])\n"
      ],
      "metadata": {
        "id": "hcIid1rQ4fCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=396)\n",
        "print(model.default_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "956db5ac7bbb4eebb589418a309ad837",
            "b1cb40e358b74de78fb1a64bee56b847",
            "13a31fb744e24a68ba0aa6f7396e074d",
            "9493eb0ff3dc4ab3a36395ce7cc4a242",
            "c729cc26c26847f39492ea8737e0fab9",
            "735254c638604abf888612285b70dbf2",
            "1dbb39f80ae04635a001e905cafb1142",
            "2296a15d13654d139317c5305e58fd53",
            "15e25a5062ee4f6a8ee1147e196a7ace",
            "42fad4ac3cdd432382122baa0981ca2b",
            "eeb91e01236c43b9b9e87718ef244f96"
          ]
        },
        "id": "95uHM81tFoKn",
        "outputId": "f232a510-65e9-41ba-8a7a-692a99b02cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "956db5ac7bbb4eebb589418a309ad837"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'url': '', 'hf_hub_id': 'timm/convnext_tiny.in12k_ft_in1k', 'architecture': 'convnext_tiny', 'tag': 'in12k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'test_input_size': (3, 288, 288), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_crop_pct': 1.0, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'stem.0', 'classifier': 'head.fc'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model.default_cfg)\n"
      ],
      "metadata": {
        "id": "IZ9btXdawzHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB Îã®ÏúÑ\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB Îã®ÏúÑ\n",
        "    print(f\"üìä ÌòÑÏû¨ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# ÌòÑÏû¨ CUDA ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏\n",
        "if torch.cuda.is_available():\n",
        "    print(\"üîç Ï¥àÍ∏∞Ìôî Ï†Ñ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU Ï∫êÏãú Î∞è Î©îÎ™®Î¶¨ Ï¥àÍ∏∞Ìôî\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\nüßπ GPU Î©îÎ™®Î¶¨ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
        "    print(\"üîç Ï¥àÍ∏∞Ìôî ÌõÑ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"‚ùå CUDA ÏÇ¨Ïö© Î∂àÍ∞Ä\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bH_WHzciHHx",
        "outputId": "2bee1269-2e84-47e4-ae46-b711325cf570"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Ï¥àÍ∏∞Ìôî Ï†Ñ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú:\n",
            "üìä ÌòÑÏû¨ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú: Allocated = 644.61 MB | Reserved = 29950.00 MB\n",
            "\n",
            "üßπ GPU Î©îÎ™®Î¶¨ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\n",
            "üîç Ï¥àÍ∏∞Ìôî ÌõÑ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú:\n",
            "üìä ÌòÑÏû¨ GPU Î©îÎ™®Î¶¨ ÏÉÅÌÉú: Allocated = 644.61 MB | Reserved = 1086.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ÏÑ§Ï†ï\n",
        "IMAGE_SIZE = 384\n",
        "ORIGIN_DIR = '/content/drive/MyDrive/open/test'\n",
        "SAVE_DIR = '/content/drive/MyDrive/open/clean_test'\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "image_paths = glob(f'{ORIGIN_DIR}/*.jpg')\n",
        "\n",
        "def resize_with_padding(img, size=384):\n",
        "    h, w = img.shape\n",
        "    scale = size / max(h, w)\n",
        "    new_h, new_w = int(h * scale), int(w * scale)\n",
        "    resized = cv2.resize(img, (new_w, new_h))\n",
        "\n",
        "    # ÏÉÅÌïòÏ¢åÏö∞ Ïó¨Î∞± Í≥ÑÏÇ∞\n",
        "    delta_w = size - new_w\n",
        "    delta_h = size - new_h\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    # Ìå®Îî©: Í≤ÄÏùÄÏÉâ(0)\n",
        "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
        "    return padded\n",
        "\n",
        "for img_path in tqdm(image_paths, desc=\"üì¶ Ï†ÑÏ≤òÎ¶¨ Ï§ë (padding Î∞©Ïãù)\"):\n",
        "    try:\n",
        "        # Grayscale Î°úÎìú\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            print(f\"‚ùå Ïù¥ÎØ∏ÏßÄ Î°úÎìú Ïã§Ìå®: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # ÎπÑÏú® Ïú†ÏßÄ + Ìå®Îî©\n",
        "        img = resize_with_padding(img, size=IMAGE_SIZE)\n",
        "\n",
        "        # Ï†ïÍ∑úÌôî (-1 ~ 1)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = (img - 0.5) / 0.5\n",
        "        img = np.expand_dims(img, axis=0)  # (1, 384, 384)\n",
        "\n",
        "        # Ï†ÄÏû• Í≤ΩÎ°ú\n",
        "        class_name = os.path.basename(os.path.dirname(img_path))\n",
        "        file_name = os.path.basename(img_path).replace('.jpg', '.npy')\n",
        "        save_class_dir = os.path.join(SAVE_DIR, class_name)\n",
        "        os.makedirs(save_class_dir, exist_ok=True)\n",
        "\n",
        "        np.save(os.path.join(save_class_dir, file_name), img)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù: {img_path} - {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv2kiYL9-RSb",
        "outputId": "eb3b7374-27dc-45f5-bd1c-b3ba4214aa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üì¶ Ï†ÑÏ≤òÎ¶¨ Ï§ë (padding Î∞©Ïãù): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8258/8258 [05:27<00:00, 25.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def extract_class_name(fname):\n",
        "    # '1ÏãúÎ¶¨Ï¶à_F20_2013_2015_000123.npy' ‚Üí '1ÏãúÎ¶¨Ï¶à_F20_2013_2015'\n",
        "    return '_'.join(os.path.basename(fname).replace('.npy', '').split('_')[:-1])\n",
        "\n",
        "# ‚úÖ ÌòÑÏû¨ train Í≤ΩÎ°ú\n",
        "all_npy_files = glob.glob('/content/drive/MyDrive/open/clean_dataset/**/*.npy', recursive=True)\n",
        "\n",
        "class_names = sorted(set(extract_class_name(f) for f in all_npy_files))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"ÌÅ¥ÎûòÏä§ Ïàò: {len(class_to_idx)}\")  # 396Í∞ú ÎÇòÏôÄÏïº Ï†ïÏÉÅ\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OMK20ohGQU1",
        "outputId": "6597aeac-f0e4-4bba-a4f4-c7f944336dd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÌÅ¥ÎûòÏä§ Ïàò: 387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CarNPYDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # üöÄ Step 1. Load npy ‚Üí tensor\n",
        "        image = np.load(path, mmap_mode='r')\n",
        "        image = torch.from_numpy(image).float()  # (1, H, W)\n",
        "\n",
        "        # üöÄ Step 2. Grayscale(1) ‚Üí RGB(3)\n",
        "        image = image.repeat(3, 1, 1)  # (3, H, W)\n",
        "\n",
        "        # üöÄ Step 3. Label Ï∂îÏ∂ú (!!! Ïó¨Í∏∞Í∞Ä Î∞òÎìúÏãú ÏûàÏñ¥Ïïº Ìï®)\n",
        "        class_name = '_'.join(os.path.basename(path).replace('.npy', '').split('_')[:-1])\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # üöÄ Step 4. Transform Ï†ÅÏö©\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # üöÄ Step 5. Return (Ïù¥ ÏãúÏ†êÏóê labelÏù¥ Î∞òÎìúÏãú Ï†ïÏùòÎêòÏñ¥Ïïº Ìï®)\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "rtI0lYOuJZt5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ï†ÑÏ≤¥ .npy ÌååÏùº Î¶¨Ïä§Ìä∏ + train/val split + DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Ï†ÑÏ≤¥ .npy ÌååÏùº\n",
        "file_list = glob.glob('/content/drive/MyDrive/open/clean_dataset/**/*.npy', recursive=True)\n",
        "\n",
        "# ÎùºÎ≤® Ï∂îÏ∂ú ‚Üí stratify Í∏∞Î∞ò split\n",
        "labels = [class_to_idx[extract_class_name(f)] for f in file_list]\n",
        "train_files, val_files = train_test_split(file_list, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "# transform\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((384, 384)),  # ‚úÖ 384Î°ú Î≥ÄÍ≤Ω\n",
        "    # transforms.ToTensor(),  # Ïù¥ÎØ∏ TensorÎùºÎ©¥ ÎπºÍ∏∞\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "train_dataset = CarNPYDataset(train_files, class_to_idx, transform)\n",
        "val_dataset = CarNPYDataset(val_files, class_to_idx, transform)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "u2DB9tCSJcmI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tNalQaGrKS5u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AdamW + weight_decay Ï∂îÍ∞Ä Ï∂îÏ≤ú (EffNet Í≥ÑÏó¥Ïóê ÎßéÏù¥ ÏÇ¨Ïö©)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "JNIgNO9AKcl1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import copy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ‚úÖ StratifiedKFold Ï†ïÏùò\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ‚úÖ 5-Fold Î£®ÌîÑ ÏãúÏûë\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(file_list, labels)):\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"üîÅ Fold {fold + 1} / 5\")\n",
        "    print(f\"==============================\\n\")\n",
        "\n",
        "    # ‚úÖ FoldÎ≥Ñ train/val split\n",
        "    train_files = [file_list[i] for i in train_idx]\n",
        "    val_files = [file_list[i] for i in val_idx]\n",
        "\n",
        "    # ‚úÖ FoldÎ≥Ñ Dataset & DataLoader\n",
        "    train_dataset = CarNPYDataset(train_files, class_to_idx, transform)\n",
        "    val_dataset = CarNPYDataset(val_files, class_to_idx, transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "    # ‚úÖ FoldÎ≥Ñ model / criterion / optimizer Ï¥àÍ∏∞Ìôî\n",
        "    model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    # ‚úÖ EarlyStopping Î≥ÄÏàò Ï¥àÍ∏∞Ìôî\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # ‚úÖ Epoch Î£®ÌîÑ\n",
        "    for epoch in range(1, 31):\n",
        "        print(f\"\\nüìå Fold {fold+1} | Epoch {epoch}\")\n",
        "\n",
        "        # === ÌïôÏäµ ===\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Train Fold {fold+1}\", leave=False)\n",
        "        for X, y in loop:\n",
        "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * X.size(0)\n",
        "            train_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        # === Í≤ÄÏ¶ù ===\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "\n",
        "        val_loop = tqdm(val_loader, desc=f\"Valid Fold {fold+1}\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loop:\n",
        "                X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "                val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # === Î°úÍ∑∏ Ï∂úÎ†• ===\n",
        "        print(f\"‚úÖ Fold {fold+1} | Epoch {epoch} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "        print(f\"‚úÖ Fold {fold+1} | Epoch {epoch} | Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # === EarlyStopping ===\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            save_path = f\"/content/drive/MyDrive/team_models/EffNetB5_fold{fold+1}.pth\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"üì¶ Best model saved for Fold {fold+1}!\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"‚ö†Ô∏è EarlyStopping patience: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # ‚úÖ Fold ÎÅùÎÇòÍ≥† Best Î™®Îç∏ Î°úÎìú\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print(f\"‚úÖ Fold {fold+1} Best model loaded.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZJkMSSKeiG",
        "outputId": "6cd9783a-75f8-422d-d31f-d197ccaea473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "üîÅ Fold 1 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "üìå Fold 1 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain Fold 1:   0%|          | 0/809 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "Valid Fold 1:   0%|          | 0/203 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 1 | Train Loss: 2.0013 | Acc: 0.5985\n",
            "‚úÖ Fold 1 | Epoch 1 | Val   Loss: 0.4340 | Acc: 0.8768\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 2 | Train Loss: 0.2645 | Acc: 0.9192\n",
            "‚úÖ Fold 1 | Epoch 2 | Val   Loss: 0.3092 | Acc: 0.9096\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 3 | Train Loss: 0.1401 | Acc: 0.9533\n",
            "‚úÖ Fold 1 | Epoch 3 | Val   Loss: 0.3221 | Acc: 0.9097\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 1 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 4 | Train Loss: 0.1325 | Acc: 0.9596\n",
            "‚úÖ Fold 1 | Epoch 4 | Val   Loss: 0.3078 | Acc: 0.9150\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 5 | Train Loss: 0.1001 | Acc: 0.9693\n",
            "‚úÖ Fold 1 | Epoch 5 | Val   Loss: 0.2594 | Acc: 0.9323\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 6 | Train Loss: 0.0974 | Acc: 0.9718\n",
            "‚úÖ Fold 1 | Epoch 6 | Val   Loss: 0.2799 | Acc: 0.9281\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 1 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 7 | Train Loss: 0.0808 | Acc: 0.9761\n",
            "‚úÖ Fold 1 | Epoch 7 | Val   Loss: 0.2783 | Acc: 0.9256\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 1 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 8 | Train Loss: 0.0728 | Acc: 0.9796\n",
            "‚úÖ Fold 1 | Epoch 8 | Val   Loss: 0.2460 | Acc: 0.9388\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 9 | Train Loss: 0.0729 | Acc: 0.9793\n",
            "‚úÖ Fold 1 | Epoch 9 | Val   Loss: 0.2448 | Acc: 0.9392\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 10 | Train Loss: 0.0645 | Acc: 0.9831\n",
            "‚úÖ Fold 1 | Epoch 10 | Val   Loss: 0.2601 | Acc: 0.9338\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 1 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 11 | Train Loss: 0.0610 | Acc: 0.9833\n",
            "‚úÖ Fold 1 | Epoch 11 | Val   Loss: 0.2441 | Acc: 0.9403\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 12 | Train Loss: 0.0470 | Acc: 0.9875\n",
            "‚úÖ Fold 1 | Epoch 12 | Val   Loss: 0.2227 | Acc: 0.9457\n",
            "üì¶ Best model saved for Fold 1!\n",
            "\n",
            "üìå Fold 1 | Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 13 | Train Loss: 0.0514 | Acc: 0.9876\n",
            "‚úÖ Fold 1 | Epoch 13 | Val   Loss: 0.3010 | Acc: 0.9290\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 1 | Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 14 | Train Loss: 0.0548 | Acc: 0.9860\n",
            "‚úÖ Fold 1 | Epoch 14 | Val   Loss: 0.2712 | Acc: 0.9385\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 1 | Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 1 | Epoch 15 | Train Loss: 0.0517 | Acc: 0.9865\n",
            "‚úÖ Fold 1 | Epoch 15 | Val   Loss: 0.2282 | Acc: 0.9437\n",
            "‚ö†Ô∏è EarlyStopping patience: 3/3\n",
            "‚õî Early stopping triggered.\n",
            "‚úÖ Fold 1 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "üîÅ Fold 2 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "üìå Fold 2 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain Fold 2:   0%|          | 0/809 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "Valid Fold 2:   0%|          | 0/203 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 1 | Train Loss: 2.0334 | Acc: 0.5911\n",
            "‚úÖ Fold 2 | Epoch 1 | Val   Loss: 0.4315 | Acc: 0.8745\n",
            "üì¶ Best model saved for Fold 2!\n",
            "\n",
            "üìå Fold 2 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 2 | Train Loss: 0.2606 | Acc: 0.9218\n",
            "‚úÖ Fold 2 | Epoch 2 | Val   Loss: 0.2762 | Acc: 0.9154\n",
            "üì¶ Best model saved for Fold 2!\n",
            "\n",
            "üìå Fold 2 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 3 | Train Loss: 0.1471 | Acc: 0.9529\n",
            "‚úÖ Fold 2 | Epoch 3 | Val   Loss: 0.3099 | Acc: 0.9125\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 2 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 4 | Train Loss: 0.1193 | Acc: 0.9637\n",
            "‚úÖ Fold 2 | Epoch 4 | Val   Loss: 0.2956 | Acc: 0.9111\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 2 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 5 | Train Loss: 0.1104 | Acc: 0.9659\n",
            "‚úÖ Fold 2 | Epoch 5 | Val   Loss: 0.2739 | Acc: 0.9232\n",
            "üì¶ Best model saved for Fold 2!\n",
            "\n",
            "üìå Fold 2 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 6 | Train Loss: 0.0925 | Acc: 0.9726\n",
            "‚úÖ Fold 2 | Epoch 6 | Val   Loss: 0.2163 | Acc: 0.9399\n",
            "üì¶ Best model saved for Fold 2!\n",
            "\n",
            "üìå Fold 2 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 7 | Train Loss: 0.0813 | Acc: 0.9758\n",
            "‚úÖ Fold 2 | Epoch 7 | Val   Loss: 0.2866 | Acc: 0.9218\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 2 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 8 | Train Loss: 0.0768 | Acc: 0.9787\n",
            "‚úÖ Fold 2 | Epoch 8 | Val   Loss: 0.2470 | Acc: 0.9318\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 2 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 2 | Epoch 9 | Train Loss: 0.0647 | Acc: 0.9816\n",
            "‚úÖ Fold 2 | Epoch 9 | Val   Loss: 0.2316 | Acc: 0.9425\n",
            "‚ö†Ô∏è EarlyStopping patience: 3/3\n",
            "‚õî Early stopping triggered.\n",
            "‚úÖ Fold 2 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "üîÅ Fold 3 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "üìå Fold 3 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain Fold 3:   0%|          | 0/809 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "Valid Fold 3:   0%|          | 0/203 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 1 | Train Loss: 1.9575 | Acc: 0.6058\n",
            "‚úÖ Fold 3 | Epoch 1 | Val   Loss: 0.4284 | Acc: 0.8689\n",
            "üì¶ Best model saved for Fold 3!\n",
            "\n",
            "üìå Fold 3 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 2 | Train Loss: 0.2537 | Acc: 0.9241\n",
            "‚úÖ Fold 3 | Epoch 2 | Val   Loss: 0.3257 | Acc: 0.9043\n",
            "üì¶ Best model saved for Fold 3!\n",
            "\n",
            "üìå Fold 3 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 3 | Train Loss: 0.1451 | Acc: 0.9553\n",
            "‚úÖ Fold 3 | Epoch 3 | Val   Loss: 0.2763 | Acc: 0.9193\n",
            "üì¶ Best model saved for Fold 3!\n",
            "\n",
            "üìå Fold 3 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 4 | Train Loss: 0.1143 | Acc: 0.9660\n",
            "‚úÖ Fold 3 | Epoch 4 | Val   Loss: 0.3367 | Acc: 0.9075\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 3 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 5 | Train Loss: 0.1143 | Acc: 0.9665\n",
            "‚úÖ Fold 3 | Epoch 5 | Val   Loss: 0.2779 | Acc: 0.9255\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 3 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 6 | Train Loss: 0.0850 | Acc: 0.9756\n",
            "‚úÖ Fold 3 | Epoch 6 | Val   Loss: 0.2721 | Acc: 0.9303\n",
            "üì¶ Best model saved for Fold 3!\n",
            "\n",
            "üìå Fold 3 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 7 | Train Loss: 0.0939 | Acc: 0.9736\n",
            "‚úÖ Fold 3 | Epoch 7 | Val   Loss: 0.2468 | Acc: 0.9382\n",
            "üì¶ Best model saved for Fold 3!\n",
            "\n",
            "üìå Fold 3 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 8 | Train Loss: 0.0710 | Acc: 0.9797\n",
            "‚úÖ Fold 3 | Epoch 8 | Val   Loss: 0.3163 | Acc: 0.9188\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 3 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 9 | Train Loss: 0.0658 | Acc: 0.9829\n",
            "‚úÖ Fold 3 | Epoch 9 | Val   Loss: 0.2582 | Acc: 0.9352\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 3 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 10 | Train Loss: 0.0667 | Acc: 0.9828\n",
            "‚úÖ Fold 3 | Epoch 10 | Val   Loss: 0.2291 | Acc: 0.9425\n",
            "üì¶ Best model saved for Fold 3!\n",
            "\n",
            "üìå Fold 3 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 11 | Train Loss: 0.0458 | Acc: 0.9882\n",
            "‚úÖ Fold 3 | Epoch 11 | Val   Loss: 0.2452 | Acc: 0.9460\n",
            "‚ö†Ô∏è EarlyStopping patience: 1/3\n",
            "\n",
            "üìå Fold 3 | Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 12 | Train Loss: 0.0531 | Acc: 0.9874\n",
            "‚úÖ Fold 3 | Epoch 12 | Val   Loss: 0.2779 | Acc: 0.9298\n",
            "‚ö†Ô∏è EarlyStopping patience: 2/3\n",
            "\n",
            "üìå Fold 3 | Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 3 | Epoch 13 | Train Loss: 0.0591 | Acc: 0.9854\n",
            "‚úÖ Fold 3 | Epoch 13 | Val   Loss: 0.2589 | Acc: 0.9388\n",
            "‚ö†Ô∏è EarlyStopping patience: 3/3\n",
            "‚õî Early stopping triggered.\n",
            "‚úÖ Fold 3 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "üîÅ Fold 4 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "üìå Fold 4 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain Fold 4:   0%|          | 0/809 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "Valid Fold 4:   0%|          | 0/203 [00:00<?, ?it/s]<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-10-10f0040b71bd>:21: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fold 4 | Epoch 1 | Train Loss: 1.9658 | Acc: 0.6044\n",
            "‚úÖ Fold 4 | Epoch 1 | Val   Loss: 0.4363 | Acc: 0.8698\n",
            "üì¶ Best model saved for Fold 4!\n",
            "\n",
            "üìå Fold 4 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid Fold 4:  11%|‚ñà‚ñè        | 23/203 [00:04<00:25,  6.97it/s, loss=0.0215]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ ÏïôÏÉÅÎ∏î Inference ÏòàÏãú (5Í∞ú Î™®Îç∏ ÌèâÍ∑†)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "# ÏÑ§Ï†ï\n",
        "FOLD_MODEL_PATHS = [\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold1.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold2.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold3.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold4.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold5.pth\",\n",
        "]\n",
        "\n",
        "TEST_DIR = \"/content/drive/MyDrive/open/clean_test/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/drive/MyDrive/open/sample_submission.csv\"\n",
        "SAVE_SUBMISSION_PATH = \"/content/drive/MyDrive/team_models/submission_fold5_ensemble.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# ÏÉòÌîå Ï†úÏ∂ú ÌååÏùºÏóêÏÑú ÌÅ¥ÎûòÏä§Î™Ö Ï∂îÏ∂ú\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' Ï†úÏô∏\n",
        "\n",
        "# ‚úÖ Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ‚úÖ ÌÖåÏä§Ìä∏Ïö© Dataset\n",
        "class TestNPYDataset(Dataset):\n",
        "    def __init__(self, npy_root, transform=None):\n",
        "        self.file_list = []\n",
        "        for root, dirs, files in os.walk(npy_root):\n",
        "            for file in files:\n",
        "                if file.endswith('.npy'):\n",
        "                    self.file_list.append(os.path.join(root, file))\n",
        "        self.file_list.sort()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = np.load(path, mmap_mode='r').copy()\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image = image.repeat(3, 1, 1)\n",
        "        image = image.contiguous()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".npy\", \"\")\n",
        "        return image, fname\n",
        "\n",
        "# ‚úÖ DataLoader\n",
        "test_dataset = TestNPYDataset(TEST_DIR, transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=4\n",
        ")\n",
        "\n",
        "# ‚úÖ ÏïôÏÉÅÎ∏î Í≤∞Í≥º Ï¥àÍ∏∞Ìôî\n",
        "ensemble_outputs = []\n",
        "\n",
        "# ‚úÖ Í∞Å Fold Î™®Îç∏ ÏàúÏÑúÎåÄÎ°ú Ï∂îÎ°†\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for fold_idx, model_path in enumerate(FOLD_MODEL_PATHS):\n",
        "    print(f\"\\nüöÄ Inference with Fold {fold_idx + 1} Model: {model_path}\")\n",
        "\n",
        "    # Î™®Îç∏ Î°úÎìú\n",
        "    model = timm.create_model('efficientnet_b5', pretrained=False, num_classes=NUM_CLASSES)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # foldÎ≥Ñ output Ï†ÄÏû•\n",
        "    fold_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in tqdm(test_loader, desc=f\"üîç Fold {fold_idx + 1} Inference\"):\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "    fold_probs = np.concatenate(fold_probs, axis=0)\n",
        "    ensemble_outputs.append(fold_probs)\n",
        "\n",
        "# ‚úÖ ÏïôÏÉÅÎ∏î ÌèâÍ∑†\n",
        "ensemble_outputs = np.stack(ensemble_outputs, axis=0)  # (num_folds, num_samples, num_classes)\n",
        "mean_outputs = np.mean(ensemble_outputs, axis=0)       # (num_samples, num_classes)\n",
        "\n",
        "# ‚úÖ Í≤∞Í≥º Ï†ÄÏû•\n",
        "results = []\n",
        "for idx, path in enumerate(test_dataset.file_list):\n",
        "    fname = os.path.basename(path).replace(\".npy\", \"\")\n",
        "    row = {\"ID\": fname}\n",
        "    row.update({class_name: mean_outputs[idx, i] for i, class_name in enumerate(column_names)})\n",
        "    results.append(row)\n",
        "\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "submission_df.to_csv(SAVE_SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ ÏïôÏÉÅÎ∏î ÏÑúÎ∏åÎØ∏ÏÖò Ï†ÄÏû• ÏôÑÎ£å: {SAVE_SUBMISSION_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k61x77gkNSDG",
        "outputId": "434af969-6415-471b-d498-83e7926f2037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîç Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [00:34<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ÏÑúÎ∏åÎØ∏ÏÖò Ï†ÄÏû• ÏôÑÎ£å: submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/submission.csv\")\n",
        "df.to_csv(\"submission_utf8sig.csv\", index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "ShGkYhOXRiw1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}